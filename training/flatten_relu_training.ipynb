{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ResNet and SparseResNet on clean images \n",
    "### Flatten ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "d = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.train_utils import train_model\n",
    "from models.resnet_FReLU import FResNet, FSparseResNet\n",
    "from utils.attacks import pgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "tr_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "vl_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "ds = CIFAR10('../data', train=True, download=True, transform=tr_transform)\n",
    "ds_test = CIFAR10('../data', train=False, download=True, transform=vl_transform)\n",
    "\n",
    "batch_size = 16\n",
    "train_dl = DataLoader(ds, batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(ds_test, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on clean images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss: 1.1052 accuracy: 0.5970, time: 0:15:15\n",
      "Epoch: 2 Validation Loss: 0.8592 accuracy: 0.6948, time: 0:15:17\n",
      "Epoch: 3 Validation Loss: 0.6882 accuracy: 0.7583, time: 0:15:20\n",
      "Epoch: 4 Validation Loss: 0.6115 accuracy: 0.7857, time: 0:15:19\n",
      "Epoch: 5 Validation Loss: 0.5860 accuracy: 0.8033, time: 0:15:20\n",
      "Epoch: 6 Validation Loss: 0.4678 accuracy: 0.8417, time: 0:15:18\n",
      "Epoch: 7 Validation Loss: 0.4677 accuracy: 0.8419, time: 0:15:19\n",
      "Epoch: 8 Validation Loss: 0.4997 accuracy: 0.8373, time: 0:15:18\n",
      "epochs_no_improve: 1/4\n",
      "Epoch: 9 Validation Loss: 0.4273 accuracy: 0.8579, time: 0:15:17\n",
      "Epoch: 10 Validation Loss: 0.3947 accuracy: 0.8681, time: 0:15:19\n",
      "Epoch: 11 Validation Loss: 0.3797 accuracy: 0.8724, time: 0:15:20\n",
      "Epoch: 12 Validation Loss: 0.3833 accuracy: 0.8715, time: 0:15:20\n",
      "epochs_no_improve: 1/4\n"
     ]
    }
   ],
   "source": [
    "model = FResNet().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', min_lr=1e-7, patience=2, verbose=True)\n",
    "\n",
    "train_model(model, train_dl, valid_dl, optimizer, loss_fn, scheduler, epochs=12, device=device)\n",
    "torch.save(model.state_dict(), \"../saved/resnet_DTL.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparseResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss: 1.3578 accuracy: 0.4939, time: 0:17:27\n",
      "Epoch: 2 Validation Loss: 0.9670 accuracy: 0.6531, time: 0:17:20\n",
      "Epoch: 3 Validation Loss: 0.8113 accuracy: 0.7167, time: 0:17:23\n",
      "Epoch: 4 Validation Loss: 0.7423 accuracy: 0.7380, time: 0:17:31\n",
      "Epoch: 5 Validation Loss: 0.6602 accuracy: 0.7723, time: 0:17:41\n",
      "Epoch: 6 Validation Loss: 0.6131 accuracy: 0.7891, time: 0:17:32\n",
      "Epoch: 7 Validation Loss: 0.5638 accuracy: 0.8051, time: 0:17:19\n"
     ]
    }
   ],
   "source": [
    "model = FSparseResNet().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', min_lr=1e-7, patience=2, verbose=True)\n",
    "\n",
    "train_model(model, train_dl, valid_dl, optimizer, loss_fn, scheduler, epochs=7, sparse=True, device=device)\n",
    "torch.save(model.state_dict(), \"../saved/sparse_resnet_DTL.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
