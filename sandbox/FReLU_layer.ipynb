{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "d = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.attacks import fgsm, pgd\n",
    "from utils.utils import plot_images\n",
    "from utils.train_utils import eval_epoch, train_model\n",
    "from models.resnet import ResNet, SparseResNet\n",
    "from models.resnet_FReLU import FResNet, FSparseResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_transform = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "vl_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "ds = MNIST('../data', train=True, download=True, transform=tr_transform)\n",
    "ds_test = MNIST('../data', train=False, download=True, transform=vl_transform)\n",
    "\n",
    "batch_size = 200\n",
    "train_dl = DataLoader(ds, batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(ds_test, batch_size, shuffle=True)\n",
    "\n",
    "for X, y in valid_dl:\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "class FlattenReLU(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, x, thresholds=None):\n",
    "        self.save_for_backward(x, thresholds)\n",
    "        x = torch.where(x > thresholds, thresholds, x) \n",
    "        x[x<0] = 0\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        x, thresholds = self.saved_tensors\n",
    "        x_grad = grad_output.clone()\n",
    "        x_grad[x>thresholds] = 0\n",
    "        x_grad[x<0] = 0\n",
    "        return x_grad, None\n",
    "\n",
    "FRelu = FlattenReLU.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML(nn.Linear):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xe = torch.stack([x]*self.weight.size(0), dim=1)\n",
    "        we = torch.stack([self.weight]*x.size(0), dim=0)\n",
    "        z, _ = (we * xe).topk(int(0.1*self.weight.size(1)))\n",
    "        thresholds = z.sum(dim=2)\n",
    "        x = F.linear(x, self.weight, self.bias)\n",
    "        return FRelu(x, thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = ML(784, 200, bias=False)\n",
    "        self.fc2 = ML(200, 10, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss: 0.8033 accuracy: 0.8428, time: 0:00:20\n",
      "Epoch: 2 Validation Loss: 0.4769 accuracy: 0.8662, time: 0:00:19\n",
      "Epoch: 3 Validation Loss: 0.4047 accuracy: 0.8704, time: 0:00:17\n",
      "Epoch: 4 Validation Loss: 0.3636 accuracy: 0.8760, time: 0:00:17\n",
      "Epoch: 5 Validation Loss: 0.3407 accuracy: 0.8823, time: 0:00:16\n",
      "Epoch: 6 Validation Loss: 0.3416 accuracy: 0.8818, time: 0:00:18\n",
      "epochs_no_improve: 1/4\n",
      "Epoch: 7 Validation Loss: 0.3211 accuracy: 0.8821, time: 0:00:16\n",
      "Epoch: 8 Validation Loss: 0.3220 accuracy: 0.8838, time: 0:00:17\n",
      "epochs_no_improve: 1/4\n",
      "Epoch: 9 Validation Loss: 0.3177 accuracy: 0.8853, time: 0:00:17\n",
      "Epoch: 10 Validation Loss: 0.3071 accuracy: 0.8866, time: 0:00:17\n",
      "Epoch: 11 Validation Loss: 0.3115 accuracy: 0.8862, time: 0:00:17\n",
      "epochs_no_improve: 1/4\n",
      "Epoch: 12 Validation Loss: 0.3039 accuracy: 0.8880, time: 0:00:16\n",
      "Epoch: 13 Validation Loss: 0.3087 accuracy: 0.8875, time: 0:00:17\n",
      "epochs_no_improve: 1/4\n",
      "Epoch: 14 Validation Loss: 0.3081 accuracy: 0.8867, time: 0:00:16\n",
      "epochs_no_improve: 2/4\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 15 Validation Loss: 0.3052 accuracy: 0.8865, time: 0:00:16\n",
      "epochs_no_improve: 3/4\n",
      "Epoch: 16 Validation Loss: 0.2953 accuracy: 0.8905, time: 0:00:16\n",
      "Epoch: 17 Validation Loss: 0.2943 accuracy: 0.8904, time: 0:00:16\n",
      "Epoch: 18 Validation Loss: 0.2946 accuracy: 0.8904, time: 0:00:17\n",
      "epochs_no_improve: 1/4\n",
      "Epoch: 19 Validation Loss: 0.2949 accuracy: 0.8900, time: 0:00:16\n",
      "epochs_no_improve: 2/4\n",
      "Epoch: 20 Validation Loss: 0.2939 accuracy: 0.8904, time: 0:00:20\n",
      "Epoch: 21 Validation Loss: 0.2933 accuracy: 0.8893, time: 0:00:16\n",
      "Epoch: 22 Validation Loss: 0.2937 accuracy: 0.8896, time: 0:00:18\n",
      "epochs_no_improve: 1/4\n",
      "Epoch: 23 Validation Loss: 0.2936 accuracy: 0.8897, time: 0:00:16\n",
      "epochs_no_improve: 2/4\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch: 24 Validation Loss: 0.2940 accuracy: 0.8904, time: 0:00:16\n",
      "epochs_no_improve: 3/4\n",
      "Epoch: 25 Validation Loss: 0.2934 accuracy: 0.8903, time: 0:00:16\n",
      "epochs_no_improve: 4/4\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "model = Net1().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', min_lr=1e-7, patience=2, verbose=True)\n",
    "\n",
    "train_model(model, train_dl, valid_dl, optimizer, loss_fn, scheduler, epochs=30, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLinear(nn.Linear):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xe = torch.stack([x]*self.weight.size(0), dim=1)\n",
    "        we = torch.stack([self.weight]*x.size(0), dim=0)\n",
    "        z, _ = (we * xe).topk(int(0.3*self.weight.size(1)))\n",
    "        thresholds = z.sum(dim=2)\n",
    "        x = F.linear(x, self.weight, self.bias)    \n",
    "        return FRelu(x, thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): myLinear(in_features=10, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = myLinear(10, 2, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000,\n",
      "         0.1000],\n",
      "        [0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
      "         1.0000]])\n",
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
      "        [10.,  9., -8., -7., -6., -5.,  4.,  3.,  2.,  1.],\n",
      "        [ 6.,  7.,  8.,  9., 10.,  5.,  4.,  3.,  2.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "w = model.fc1.weight.clone()\n",
    "w = torch.Tensor([[1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1], \n",
    "                  [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "                 ])\n",
    "x = torch.Tensor([[1,2,3,4,5,6,7,8,9,10], [10,9,-8,-7,-6,-5,4,3,2,1], [6,7,8,9,10,5,4,3,2,1]])\n",
    "model.fc1.weight.data = w\n",
    "print(model.fc1.weight.data)\n",
    "print(x)\n",
    "y = torch.Tensor([1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]],\n",
       "\n",
       "        [[10.,  9., -8., -7., -6., -5.,  4.,  3.,  2.,  1.],\n",
       "         [10.,  9., -8., -7., -6., -5.,  4.,  3.,  2.,  1.]],\n",
       "\n",
       "        [[ 6.,  7.,  8.,  9., 10.,  5.,  4.,  3.,  2.,  1.],\n",
       "         [ 6.,  7.,  8.,  9., 10.,  5.,  4.,  3.,  2.,  1.]]])"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xe = torch.stack([x]*w.size(0), dim=1)\n",
    "xe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000,\n",
       "          0.2000, 0.1000],\n",
       "         [0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
       "          0.9000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000,\n",
       "          0.2000, 0.1000],\n",
       "         [0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
       "          0.9000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000,\n",
       "          0.2000, 0.1000],\n",
       "         [0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
       "          0.9000, 1.0000]]])"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we = torch.stack([w]*x.size(0), dim=0)\n",
    "we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  1.8000,  2.4000,  2.8000,  3.0000,  3.0000,  2.8000,\n",
       "           2.4000,  1.8000,  1.0000],\n",
       "         [ 0.1000,  0.4000,  0.9000,  1.6000,  2.5000,  3.6000,  4.9000,\n",
       "           6.4000,  8.1000, 10.0000]],\n",
       "\n",
       "        [[10.0000,  8.1000, -6.4000, -4.9000, -3.6000, -2.5000,  1.6000,\n",
       "           0.9000,  0.4000,  0.1000],\n",
       "         [ 1.0000,  1.8000, -2.4000, -2.8000, -3.0000, -3.0000,  2.8000,\n",
       "           2.4000,  1.8000,  1.0000]],\n",
       "\n",
       "        [[ 6.0000,  6.3000,  6.4000,  6.3000,  6.0000,  2.5000,  1.6000,\n",
       "           0.9000,  0.4000,  0.1000],\n",
       "         [ 0.6000,  1.4000,  2.4000,  3.6000,  5.0000,  3.0000,  2.8000,\n",
       "           2.4000,  1.8000,  1.0000]]])"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(we * xe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.0000,  3.0000,  2.8000],\n",
      "         [10.0000,  8.1000,  6.4000]],\n",
      "\n",
      "        [[10.0000,  8.1000,  1.6000],\n",
      "         [ 2.8000,  2.4000,  1.8000]],\n",
      "\n",
      "        [[ 6.4000,  6.3000,  6.3000],\n",
      "         [ 5.0000,  3.6000,  3.0000]]])\n"
     ]
    }
   ],
   "source": [
    "val, _ = (we * xe).topk(int(0.3*w.size(1)))\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.8000, 24.5000],\n",
      "        [19.7000,  7.0000],\n",
      "        [19.0000, 11.6000]])\n"
     ]
    }
   ],
   "source": [
    "thresholds = val.sum(dim=-1)\n",
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.8000, 24.5000],\n",
       "        [ 3.7000,  0.0000],\n",
       "        [19.0000, 11.6000]])"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = x @ w.T\n",
    "f = torch.where(res > thresholds, thresholds, res)\n",
    "f[f<0]=0\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.8000, 24.5000],\n",
       "        [ 3.7000,  0.0000],\n",
       "        [19.0000, 11.6000]], grad_fn=<FlattenReLUBackward>)"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.0000, 38.5000],\n",
       "        [ 3.7000, -0.4000],\n",
       "        [36.5000, 24.0000]])"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
